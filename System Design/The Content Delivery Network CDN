CDN (Content Delivery Network) is designed to solve several problems that arise when millions of users worldwide use data-intensive applications that are served from a single data center. Let's understand these problems in simpler terms:

  1. High latency: Latency refers to the delay between a user's request and the response they receive. When the data center is far away from the user, it results in high latency due to factors like distance, network congestion, and processing delays. Real-time applications like voice or video streaming require low latency for a smooth user experience. CDN helps reduce latency by bringing the content closer to the users, minimizing the physical distance data needs to travel.

  2. Data-intensive applications: Data-intensive applications generate large amounts of traffic. When this traffic needs to travel over long distances, it can lead to network issues like reduced throughput and congestion. Additionally, the origin server in the data center may have to send the same data to multiple users individually, causing redundant data transmission. CDN addresses these problems by caching and distributing content across multiple servers located in different regions. Users can then access the content from nearby servers, reducing network strain and improving performance.

  3. Scarcity of data center resources: As the number of users increases, a single data center may struggle to handle the growing demand. Limited computational capacity and bandwidth become bottlenecks, affecting the scalability and reliability of the service. CDN tackles this issue by distributing the load across multiple servers and data centers. By leveraging a network of geographically dispersed servers, CDN ensures that resources are efficiently utilized, enabling better scalability and reducing the risk of a single point of failure.

In summary, CDN solves the problems of high latency, handling data-intensive applications, and addressing resource limitations in a single data center by distributing content to multiple servers and data centers closer to the users. This improves performance, reduces network congestion, and enhances the overall user experience.

Proposed solution:
A content delivery network (CDN) is the solution to the problems we discussed earlier. It is a group of proxy servers distributed geographically. A proxy server acts as an intermediate server between the client and the origin server. These proxy servers are placed at the network edge, close to the end users, to quickly deliver content by reducing latency and saving bandwidth. CDNs go beyond being simple proxy servers and provide additional intelligence.

To bring data closer to users, CDNs store copies of static and dynamic data in small data centers near users. CDN providers focus on reducing propagation delay by bringing the data closer to users and ensuring sufficient bandwidth availability through the path. By doing so, they can minimize transmission and queuing delays.

  CDNs solve the discussed problems in the following ways:
  1. High latency: CDNs bring content closer to end users, reducing physical distance and latency.
  2. Data-intensive applications: CDNs serve a large number of users through a few CDN components in a specific area, minimizing issues. The origin data center provides data to local CDN components only once, and local CDN components can then serve different users individually without each user having to download their own copy from the origin servers.
  3. Scarcity of data center resources: CDNs handle most of the traffic for popular content, relieving the load on origin servers. Local or distributed CDN components share the load, ensuring efficient resource utilization.

Requirements:
Functional and non-functional requirements for a CDN.

Functional requirements:
  - Retrieve: The CDN should be able to retrieve content from the origin servers based on the CDN model being used.
  - Request: CDN proxy servers should respond to user requests for content delivery.
  - Deliver: In a push model, origin servers should be able to send content to CDN proxy servers.
  - Search: The CDN should execute searches against user queries to find cached or stored content within the CDN infrastructure.
  - Update: If there are scripts running in the CDN, it should be able to update content within peer CDN proxy servers.
  - Delete: The CDN should have the ability to delete cached entries from CDN servers based on the type of content (static or dynamic).

Non-functional requirements:
  - Performance: The CDN design should minimize latency, providing a low-delay user experience.
  - Availability: CDNs should be available at all times, with protection against attacks like Distributed Denial of Service (DDoS).
  - Scalability: The CDN design should scale horizontally to handle increasing user requests.
  - Reliability and security: The CDN should be reliable, avoiding single points of failure, and capable of handling massive traffic loads. It should also provide protection against various attacks.

Building blocks:
The design of a CDN incorporates the following building blocks:
  - DNS: Maps CDN domain names to IP addresses, directing users to the specified proxy server.
  - Load balancers: Distribute requests among operational proxy servers, ensuring efficient load distribution.

In summary, a CDN is a network of geographically distributed proxy servers that bring data closer to users, reducing latency and addressing issues with data-intensive applications. It satisfies functional requirements like content retrieval, delivery, and search, while meeting non-functional requirements such as performance, availability, scalability, reliability, and security. The CDN design utilizes building blocks like DNS and load balancers to enable efficient content delivery.

Design of CDN system

    Basic design of a CDN (Content Delivery Network) system. We'll cover the different components of a CDN, the workflow of how these components interact, and the API design for various functionalities.

    CDN Components:
    A CDN system consists of the following components:

    1. Clients: These are the end users who request content from the CDN using browsers, smartphones, or other devices.

    2. Routing System: The routing system directs clients to the nearest CDN facility. It gathers information about content placement, request volume, server load, and URI namespace to efficiently route users to the appropriate CDN facility.

    3. Scrubber Servers: Scrubber servers separate legitimate traffic from malicious traffic and protect against attacks like DDoS. They are activated only when an attack is detected.

    4. Proxy Servers: Proxy servers, also known as edge proxy servers, store and serve content to users. They store frequently accessed data in RAM and can also store less frequently accessed data on SSD or hard drives. Proxy servers also handle accounting information and receive content from the distribution system.

    5. Distribution System: The distribution system is responsible for distributing content to the edge proxy servers across different CDN facilities. It uses intelligent broadcast-like approaches and the Internet to efficiently distribute content.

    6. Origin Servers: The origin servers provide the CDN infrastructure with data. They serve any unavailable data at the CDN to clients. The internal architecture of the origin infrastructure is not discussed here.

    7. Management System: The management systems monitor resource usage and statistics in the CDN. They measure important metrics such as latency, downtime, packet loss, and server load. For third-party CDNs, accounting information can be used for billing purposes.

    Workflow:
    The workflow of a CDN system follows these steps:

    1. Origin servers delegate the URI namespace of cached objects to the request routing system.

    2. Origin servers publish content to the distribution system, which distributes the content among the proxy servers and provides feedback to the routing system. This feedback helps optimize the selection of the nearest proxy server for clients.

    3. Clients request a suitable proxy server from the routing system.

    4. The request routing system returns the IP address of an appropriate proxy server.

    5. The client's request passes through scrubber servers for security reasons.

    6. The scrubber server forwards legitimate traffic to the edge proxy server.

    7. The edge proxy server serves the client's request and periodically sends accounting information to the management system. If the requested content is not available in the proxy servers, the request may be routed to origin servers or parent proxy servers in a hierarchy.

    API Design:
    The CDN system uses APIs for various functionalities. Here are the APIs for different operations:

    1. Retrieve Content (proxy server to origin server):
      - API: retrieveContent(proxyserver_id, content_type, content_version, description)
      - This API retrieves content from the origin server based on the provided parameters.

    2. Deliver Content (origin server to proxy servers):
      - API: deliverContent(origin_id, server_list, content_type, content_version, description)
      - This API delivers updated content from the origin server to the proxy servers.

    3. Request Content (clients to proxy servers):
      - API: requestContent(user_id, content_type, description)
      - Clients use this API to request content from the proxy servers.

    4. Search Content (proxy server to peer proxy servers):
      - API: searchContent(proxyserver_id, content_type, description)
      - Proxy servers can search for requested content in peer proxy servers within the same Point of Presence (PoP).

    5. Update Content (proxy server to peer proxy servers):
      - API: updateContent(proxyserver_id, content_type, description)
      - Proxy servers use this API to update specified content in peer proxy servers

Understanding Content Delivery Networks (CDNs): Part 1

Introduction:
In this lesson, we will explore the fundamentals of Content Delivery Networks (CDNs). Specifically, we will focus on two models used in CDNs: push and pull models. We will also discuss dynamic content caching optimization and various techniques for discovering nearby proxy servers in CDNs.

1. Content caching strategies in CDNs:
CDNs utilize content caching to deliver up-to-date and popular web content. There are two classifications of CDNs based on how they obtain content from origin servers:

a. Push CDN:
- In the push CDN model, content is automatically sent from the origin server to the CDN proxy servers.
- The responsibility for delivering content to the CDN proxy servers lies with the content provider.
- Push CDN is suitable for static content delivery, where the origin server determines which content to send to users via the CDN.
- Content is pushed to proxy servers in different locations based on its popularity.
- However, if the content changes rapidly, the push model may struggle to keep up and result in redundant content pushes.

b. Pull CDN:
- In the pull CDN model, a CDN retrieves unavailable data from origin servers when requested by a user.
- Proxy servers keep the files for a specified time and remove them from the cache if they are no longer requested, balancing capacity and cost.
- When users request web content, the CDN pulls the content from the origin server and serves it to the users.
- Pull CDNs are better suited for serving dynamic content that frequently changes.
- Pull CDNs have the advantage of low storage consumption compared to push CDNs.

Note: Many content providers use a combination of both push and pull CDN caching approaches to leverage their respective benefits.

2. Dynamic content caching optimization:
Optimizing the caching of dynamic content is essential due to its frequent changes. Here are some optimization techniques:

a. Execution of scripts at proxy servers:
- Certain dynamic content creation involves scripts that can be executed at proxy servers instead of the origin server.
- Running these scripts at proxy servers can be beneficial, generating dynamic content based on parameters such as user location, time of day, third-party APIs, etc.

b. Compression techniques:
- Compression techniques, like Railgun used by Cloudflare, can be employed to reduce communication between origin servers and proxy servers.
- Compressing dynamic content helps minimize storage requirements at proxy servers.

c. Edge Side Includes (ESI):
- ESI is a markup language that helps optimize dynamic content caching.
- It specifies where content has changed in a web page, allowing the rest of the content to be cached.
- CDN providers often use ESI, although it is not yet standardized by the W3C.

3. Multi-tier CDN architecture:
To efficiently distribute content to CDN proxy servers, a multi-tier architecture is commonly used. Here's how it works:

- Content providers send data to a large number of clients through a CDN.
- Distributing data simultaneously to all CDN proxy servers can burden the origin server.
- CDNs utilize a tree-like structure for data distribution, reducing the burden on the origin server.
- Edge proxy servers have peer servers within the same hierarchy, receiving data from parent nodes in the tree, ultimately receiving it from the origin servers.
- The tree structure allows scalability by adding more server nodes to accommodate increasing users.
- CDNs typically have one or two tiers of proxy servers, simplifying data distribution.

4. Finding the nearest proxy server to fetch data:
To minimize user-perceived latency, it is crucial to fetch data from the nearest proxy server. Consider these important factors:

a. Network distance:
- The length of the network path and its capacity (bandwidth) influence the network distance between the user and the proxy server.
- The shortest path with the highest capacity

 is the nearest proxy server, allowing faster content downloads.

b. Requests load:
- Proxy servers handle varying loads at different times.
- A request routing system should forward requests to locations with lesser load, balancing the load among proxy servers and reducing response latency.

Techniques used to route users to the nearest proxy server include:

- DNS redirection: Content providers use DNS redirects to direct clients to specific CDNs, considering network distance and load balancing.
- Anycast: Routing methodology where multiple edge servers share the same IP address, directing clients to the nearest proxy servers.
- Client multiplexing: Involves providing a list of candidate servers to the client, allowing them to choose one. However, this approach may result in inefficient server selection.
- HTTP redirection: The client requests content from the origin server, which responds with an HTTP redirect to the CDN's URL for content retrieval.

Conclusion:
Understanding CDN models, dynamic content caching optimization, multi-tier architecture, and techniques for finding the nearest proxy server enhances our comprehension of CDNs' functionality and performance optimization.
