CDN (Content Delivery Network) is designed to solve several problems that arise when millions of users worldwide use data-intensive applications that are served from a single data center. Let's understand these problems in simpler terms:

  1. High latency: Latency refers to the delay between a user's request and the response they receive. When the data center is far away from the user, it results in high latency due to factors like distance, network congestion, and processing delays. Real-time applications like voice or video streaming require low latency for a smooth user experience. CDN helps reduce latency by bringing the content closer to the users, minimizing the physical distance data needs to travel.

  2. Data-intensive applications: Data-intensive applications generate large amounts of traffic. When this traffic needs to travel over long distances, it can lead to network issues like reduced throughput and congestion. Additionally, the origin server in the data center may have to send the same data to multiple users individually, causing redundant data transmission. CDN addresses these problems by caching and distributing content across multiple servers located in different regions. Users can then access the content from nearby servers, reducing network strain and improving performance.

  3. Scarcity of data center resources: As the number of users increases, a single data center may struggle to handle the growing demand. Limited computational capacity and bandwidth become bottlenecks, affecting the scalability and reliability of the service. CDN tackles this issue by distributing the load across multiple servers and data centers. By leveraging a network of geographically dispersed servers, CDN ensures that resources are efficiently utilized, enabling better scalability and reducing the risk of a single point of failure.

In summary, CDN solves the problems of high latency, handling data-intensive applications, and addressing resource limitations in a single data center by distributing content to multiple servers and data centers closer to the users. This improves performance, reduces network congestion, and enhances the overall user experience.

Proposed solution:
A content delivery network (CDN) is the solution to the problems we discussed earlier. It is a group of proxy servers distributed geographically. A proxy server acts as an intermediate server between the client and the origin server. These proxy servers are placed at the network edge, close to the end users, to quickly deliver content by reducing latency and saving bandwidth. CDNs go beyond being simple proxy servers and provide additional intelligence.

To bring data closer to users, CDNs store copies of static and dynamic data in small data centers near users. CDN providers focus on reducing propagation delay by bringing the data closer to users and ensuring sufficient bandwidth availability through the path. By doing so, they can minimize transmission and queuing delays.

  CDNs solve the discussed problems in the following ways:
  1. High latency: CDNs bring content closer to end users, reducing physical distance and latency.
  2. Data-intensive applications: CDNs serve a large number of users through a few CDN components in a specific area, minimizing issues. The origin data center provides data to local CDN components only once, and local CDN components can then serve different users individually without each user having to download their own copy from the origin servers.
  3. Scarcity of data center resources: CDNs handle most of the traffic for popular content, relieving the load on origin servers. Local or distributed CDN components share the load, ensuring efficient resource utilization.

Requirements:
Functional and non-functional requirements for a CDN.

Functional requirements:
  - Retrieve: The CDN should be able to retrieve content from the origin servers based on the CDN model being used.
  - Request: CDN proxy servers should respond to user requests for content delivery.
  - Deliver: In a push model, origin servers should be able to send content to CDN proxy servers.
  - Search: The CDN should execute searches against user queries to find cached or stored content within the CDN infrastructure.
  - Update: If there are scripts running in the CDN, it should be able to update content within peer CDN proxy servers.
  - Delete: The CDN should have the ability to delete cached entries from CDN servers based on the type of content (static or dynamic).

Non-functional requirements:
  - Performance: The CDN design should minimize latency, providing a low-delay user experience.
  - Availability: CDNs should be available at all times, with protection against attacks like Distributed Denial of Service (DDoS).
  - Scalability: The CDN design should scale horizontally to handle increasing user requests.
  - Reliability and security: The CDN should be reliable, avoiding single points of failure, and capable of handling massive traffic loads. It should also provide protection against various attacks.

Building blocks:
The design of a CDN incorporates the following building blocks:
  - DNS: Maps CDN domain names to IP addresses, directing users to the specified proxy server.
  - Load balancers: Distribute requests among operational proxy servers, ensuring efficient load distribution.

In summary, a CDN is a network of geographically distributed proxy servers that bring data closer to users, reducing latency and addressing issues with data-intensive applications. It satisfies functional requirements like content retrieval, delivery, and search, while meeting non-functional requirements such as performance, availability, scalability, reliability, and security. The CDN design utilizes building blocks like DNS and load balancers to enable efficient content delivery.

Design of CDN system

    Basic design of a CDN (Content Delivery Network) system. We'll cover the different components of a CDN, the workflow of how these components interact, and the API design for various functionalities.

    CDN Components:
    A CDN system consists of the following components:

    1. Clients: These are the end users who request content from the CDN using browsers, smartphones, or other devices.

    2. Routing System: The routing system directs clients to the nearest CDN facility. It gathers information about content placement, request volume, server load, and URI namespace to efficiently route users to the appropriate CDN facility.

    3. Scrubber Servers: Scrubber servers separate legitimate traffic from malicious traffic and protect against attacks like DDoS. They are activated only when an attack is detected.

    4. Proxy Servers: Proxy servers, also known as edge proxy servers, store and serve content to users. They store frequently accessed data in RAM and can also store less frequently accessed data on SSD or hard drives. Proxy servers also handle accounting information and receive content from the distribution system.

    5. Distribution System: The distribution system is responsible for distributing content to the edge proxy servers across different CDN facilities. It uses intelligent broadcast-like approaches and the Internet to efficiently distribute content.

    6. Origin Servers: The origin servers provide the CDN infrastructure with data. They serve any unavailable data at the CDN to clients. The internal architecture of the origin infrastructure is not discussed here.

    7. Management System: The management systems monitor resource usage and statistics in the CDN. They measure important metrics such as latency, downtime, packet loss, and server load. For third-party CDNs, accounting information can be used for billing purposes.

    Workflow:
    The workflow of a CDN system follows these steps:

    1. Origin servers delegate the URI namespace of cached objects to the request routing system.

    2. Origin servers publish content to the distribution system, which distributes the content among the proxy servers and provides feedback to the routing system. This feedback helps optimize the selection of the nearest proxy server for clients.

    3. Clients request a suitable proxy server from the routing system.

    4. The request routing system returns the IP address of an appropriate proxy server.

    5. The client's request passes through scrubber servers for security reasons.

    6. The scrubber server forwards legitimate traffic to the edge proxy server.

    7. The edge proxy server serves the client's request and periodically sends accounting information to the management system. If the requested content is not available in the proxy servers, the request may be routed to origin servers or parent proxy servers in a hierarchy.

    API Design:
    The CDN system uses APIs for various functionalities. Here are the APIs for different operations:

    1. Retrieve Content (proxy server to origin server):
      - API: retrieveContent(proxyserver_id, content_type, content_version, description)
      - This API retrieves content from the origin server based on the provided parameters.

    2. Deliver Content (origin server to proxy servers):
      - API: deliverContent(origin_id, server_list, content_type, content_version, description)
      - This API delivers updated content from the origin server to the proxy servers.

    3. Request Content (clients to proxy servers):
      - API: requestContent(user_id, content_type, description)
      - Clients use this API to request content from the proxy servers.

    4. Search Content (proxy server to peer proxy servers):
      - API: searchContent(proxyserver_id, content_type, description)
      - Proxy servers can search for requested content in peer proxy servers within the same Point of Presence (PoP).

    5. Update Content (proxy server to peer proxy servers):
      - API: updateContent(proxyserver_id, content_type, description)
      - Proxy servers use this API to update specified content in peer proxy servers